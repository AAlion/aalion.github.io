<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Java,框架学习," />










<meta name="description" content="@TOC 一、Kafka概念1. 概念 1 定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 总结：是一个分布式消息队列，流式计算中，一般用来缓存数据，具有统一、高吞吐、低等待的特性。 具体：在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。1）Apache  Kafka是一个开源消息系统，由">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka初识">
<meta property="og:url" content="http://yoursite.com/2021/01/01/Java001/index.html">
<meta property="og:site_name" content="AAlion">
<meta property="og:description" content="@TOC 一、Kafka概念1. 概念 1 定义Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。 总结：是一个分布式消息队列，流式计算中，一般用来缓存数据，具有统一、高吞吐、低等待的特性。 具体：在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。1）Apache  Kafka是一个开源消息系统，由">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327111441704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327131042798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327130558619.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327132556852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327132948649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210408112934730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327134938950.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2021032714065464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327140820226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327140029551.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327140112684.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327142750343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327142856385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327150604199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327160307743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327160446451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_10,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/202103271608335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/202103271612173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327161524488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327161730584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327191241434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327191625484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327192145969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327200206246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210327212719353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210328135809288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210328161857456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20210328164438403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2021-01-01T00:00:01.000Z">
<meta property="article:modified_time" content="2021-04-15T07:06:11.576Z">
<meta property="article:author" content="AAlion">
<meta property="article:tag" content="Java">
<meta property="article:tag" content="框架学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20210327111441704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/01/01/Java001/"/>





  <title>Kafka初识 | AAlion</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AAlion</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">我走得很慢，但我从不后退</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/01/Java001/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AAlion">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AAlion">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kafka初识</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-01T00:00:01+00:00">
                2021-01-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>@<a href="目录">TOC</a></p>
<h2 id="一、Kafka概念"><a href="#一、Kafka概念" class="headerlink" title="一、Kafka概念"></a>一、Kafka概念</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h3><ul>
<li><strong>1 定义</strong><br>Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</li>
<li>总结：<br>是一个分布式消息队列，流式计算中，一般用来缓存数据，具有统一、高吞吐、低等待的特性。</li>
<li>具体：<br>在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。<br>1）Apache  Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。<br>2）Kafka最初是由LinkedIn公司开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。<br>3）Kafka是一个分布式消息队列。Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer，消息接受者称为Consumer，此外kafka集群有多个kafka实例组成，每个实例(server)称为broker。<br>4）无论是kafka集群，还是consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性。</li>
</ul>
<h3 id="2-Kafka架构"><a href="#2-Kafka架构" class="headerlink" title="2. Kafka架构"></a>2. Kafka架构</h3><h4 id="1-基础架构"><a href="#1-基础架构" class="headerlink" title="1-基础架构"></a>1-基础架构</h4><p>1）Producer ：消息生产者，就是向kafka broker发消息的客户端；<br>2）Consumer ：消息消费者，向kafka broker取消息的客户端；<br>3）Consumer Group （CG）：消费者组，由多个consumer组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。</strong>所有的消费者都属于某个消费者组，即<strong>消费者组是逻辑上的一个订阅者</strong>。<br>4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。<br>5）Topic ：可以理解为一个队列，<strong>生产者和消费者面向的都是一个topic</strong>；<br>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，<strong>一个topic可以分为多个partition</strong>，每个partition是一个有序的队列；<br>7）Replica：副本，为保证集群中的某个节点发生故障时，<strong>该节点上的partition数据不丢失，且kafka仍然能够继续工作</strong>，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。<br>8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。<br>9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。<br><img src="https://img-blog.csdnimg.cn/20210327111441704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="2-工作流程及文件存储机制"><a href="#2-工作流程及文件存储机制" class="headerlink" title="2-工作流程及文件存储机制"></a>2-工作流程及文件存储机制</h4><h6 id="1-工作流程"><a href="#1-工作流程" class="headerlink" title="1 工作流程"></a>1 工作流程</h6><p>– Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p>
<p>tips：Kafka只能保证区内有序，而不能保证全局有序<br><img src="https://img-blog.csdnimg.cn/20210327131042798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>官网图：<br><img src="https://img-blog.csdnimg.cn/20210327130558619.png" alt=""></p>
<h6 id="2-文件存储机制-日志结构"><a href="#2-文件存储机制-日志结构" class="headerlink" title="2 文件存储机制 -日志结构"></a>2 文件存储机制 -日志结构</h6><p>– topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。<br><img src="https://img-blog.csdnimg.cn/20210327132556852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>– 由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了<strong>分片和索引机制</strong>，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>
<p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图:<br><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据</strong>，索引文件中的元数据指向对应数据文件中message的物理偏移地址。<br>tips：索引信息还包含对应数据的大小、seed方法<br><img src="https://img-blog.csdnimg.cn/20210327132948649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>补充：</strong><br>日志中包含多个日志段，而每个日志段又包含：消息日志文件、位移索引文件、时间戳索引文件、已终止的事务索引文件。<br><img src="https://img-blog.csdnimg.cn/20210408112934730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="3-生产者"><a href="#3-生产者" class="headerlink" title="3-生产者"></a>3-生产者</h4><h5 id="1-gt-分区策略"><a href="#1-gt-分区策略" class="headerlink" title="1&gt; 分区策略"></a>1&gt; 分区策略</h5><ul>
<li><strong>1）分区的原因</strong><br>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；—注：即负载均衡<br>（2）可以提高并发，因为可以以Partition为单位读写了。</li>
<li><strong>2）分区的原则</strong><br>我们需要将producer发送的数据封装成一个<strong>ProducerRecord对象</strong>。<br>（1）指明partition 的情况下，直接将指明的值直接作为partiton 值；<br>（2）没有指明partition 值但有key 的情况下，将key 的hash 值与topic 的partition 数进行取余得到partition 值；<br>（3）既没有partition 值又没有key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic 可用的partition 总数取余得到partition 值，也就是常说的round-robin 算法<br><img src="https://img-blog.csdnimg.cn/20210327134938950.png" alt="在这里插入图片描述"></li>
</ul>
<h5 id="2-gt-数据可靠性保证—重复、一致"><a href="#2-gt-数据可靠性保证—重复、一致" class="headerlink" title="2&gt; 数据可靠性保证—重复、一致"></a>2&gt; 数据可靠性保证—重复、一致</h5><ul>
<li><strong>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</strong><br><img src="https://img-blog.csdnimg.cn/2021032714065464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li><strong>1）副本数据同步策略</strong><br>Kafka选择了第二种方案，原因如下：</li>
</ul>
<p>1.同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。<br>2.虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。<br><img src="https://img-blog.csdnimg.cn/20210327140820226.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><strong>2）ISR</strong></li>
</ul>
<p>– 问题：<br>采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？<br>– 解决：<br><strong>Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</strong><br>tips：满足replica.lag.time.max.ms参数设置内时间，follower被加入ISR，ISR全部同步完，即完成，<br>0.9之前还有个同步条数参数，后被移除<br>ISR包含leader<br>10s<br><img src="https://img-blog.csdnimg.cn/20210327140029551.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210327140112684.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><strong>3）ack应答机制</strong></li>
</ul>
<p>– 不重要的数据：<br>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower（ISR）全部接收成功。<br>– 三种可靠级别：<br>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。<br><strong>acks参数配置</strong>：<br><strong>acks：</strong><br>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能<strong>丢失数据</strong>；<br>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会<strong>丢失数据</strong>；<br><img src="https://img-blog.csdnimg.cn/20210327142750343.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成==数据重复==。<br>tips:leader保存数据后未发生ack挂掉，生产者没收到ack，向新leader重新发送，新leader重新保存数据。<br><img src="https://img-blog.csdnimg.cn/20210327142856385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><strong>4）故障处理细节</strong></li>
<li><em>LEO：指的是每个副本最大的offset；*</em></li>
<li><em>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。*</em><br>（1）follower故障<br>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。<br>（2）leader故障<br>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。（注：多了会截取，少了会同步补上）<br>==注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。==<br>tips：保证了消费一致性 存储一致性，ack 处理数据丢失和重复，此处的leader和follower都是ISR中的。<br>Log文件中的HW和LEO，如图：<br><img src="https://img-blog.csdnimg.cn/20210327150604199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
</ul>
<h5 id="3-gt-Exactly-Once语义—精准一次性"><a href="#3-gt-Exactly-Once语义—精准一次性" class="headerlink" title="3&gt; Exactly Once语义—精准一次性"></a>3&gt; Exactly Once语义—精准一次性</h5><ul>
<li><strong>1 AtLeast Once语义：</strong> 至少一次<br>将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即AtLeast Once语义。</li>
<li><strong>2 AtMostOnce语义：</strong>至多一次<br>相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即AtMostOnce语义。</li>
<li><strong>3 重复、丢失</strong><br>AtLeastOnce可以保证数据不丢失，但是不能保证数据不重复；相对的，AtLeastOnce可以保证数据不重复，但是不能保证数据不丢失。但是，<strong>对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即ExactlyOnce语义。</strong>在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</li>
<li><strong>4 幂等性</strong></li>
</ul>
<p>0.11版本的Kafka，引入了一项重大特性：幂等性。<br>所谓的<strong>幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条</strong>。幂等性结合AtLeastOnce语义，就构成了Kafka的ExactlyOnce语义。即：<br>AtLeastOnce+幂等性=ExactlyOnce</p>
<ul>
<li><strong>5 启用幂等性</strong><br>要启用幂等性，只需要将Producer的参数中enable.idompotence设置为true即可（注，即ack=-1）。</li>
<li><strong>6 幂等实现</strong><br>Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带SequenceNumber。而<strong>Broker端</strong>会对&lt;PID, Partition,SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。<br>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的ExactlyOnce。（注，重新建立会话，pid变化，重新发送幂等会失效）</li>
</ul>
<h4 id="4-消费者"><a href="#4-消费者" class="headerlink" title="4-消费者"></a>4-消费者</h4><h5 id="1-gt-消费方式"><a href="#1-gt-消费方式" class="headerlink" title="1&gt; 消费方式"></a>1&gt; 消费方式</h5><ul>
<li>==consumer采用pull（拉）模式从broker中读取数据。==</li>
<li><strong>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。</strong><br>它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</li>
<li><strong>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。</strong>针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</li>
</ul>
<h5 id="2-gt-分区分配策略"><a href="#2-gt-分区分配策略" class="headerlink" title="2&gt; 分区分配策略"></a>2&gt; 分区分配策略</h5><ul>
<li><strong>1 分配问题</strong><br>一个consumergroup中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。</li>
<li><strong>2 Kafka有两种分配策略</strong><br>一是RoundRobin，一是Range（默认）。<br>（注，消费者增减需要重分配。RoundRobin直接看那个组订阅了它，组订阅了就把T1T2轮询给组，Range优先看消费者，然后再看消费者分组，/2分配给消费者组）<br>一个topic的消费，如下：<br><img src="https://img-blog.csdnimg.cn/20210327160307743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>1）RoundRobin<br>好处：最多差一个<br>弊端：订阅主体一样才能使用<br><img src="https://img-blog.csdnimg.cn/20210327160446451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_10,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>多topic：<br><img src="https://img-blog.csdnimg.cn/202103271608335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>问题：<br><img src="https://img-blog.csdnimg.cn/202103271612173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210327161524488.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>2）Range<br>缺点：数据不均衡<br><img src="https://img-blog.csdnimg.cn/20210327161730584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>组        topic<br>轮询      面向主体  不均衡</li>
</ul>
<h5 id="3-gt-offset的维护"><a href="#3-gt-offset的维护" class="headerlink" title="3&gt; offset的维护"></a>3&gt; offset的维护</h5><p>– 由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。<br>– Kafka0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。<br><img src="https://img-blog.csdnimg.cn/20210327191241434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="4-gt-消费者组案例"><a href="#4-gt-消费者组案例" class="headerlink" title="4&gt; 消费者组案例"></a>4&gt; 消费者组案例</h5><p>1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。</p>
<h4 id="5-Kafka-高效读写数据"><a href="#5-Kafka-高效读写数据" class="headerlink" title="5-Kafka 高效读写数据"></a>5-Kafka 高效读写数据</h4><p>1）顺序写磁盘<br>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。<br>2）零复制技术<br>正常io不包含中间那条线<br><img src="https://img-blog.csdnimg.cn/20210327191625484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>零拷贝：<br><img src="https://img-blog.csdnimg.cn/20210327192145969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="6-Zookeeper在Kafka中的作用"><a href="#6-Zookeeper在Kafka中的作用" class="headerlink" title="6-Zookeeper在Kafka中的作用"></a>6-Zookeeper在Kafka中的作用</h4><p>Kafka集群中有一个broker会被选举为Controller，负责<strong>管理集群broker的上下线</strong>，所有<strong>topic的分区副本分配和leader选举等工作</strong>。Controller的管理工作都是依赖于Zookeeper的。<br>tiips：controller选举：隔断时间看一下controller是否还在，先到先得 （Controller是kafka实例，leader是数据副本）<br>以下为partition的leader选举过程：<br><img src="https://img-blog.csdnimg.cn/20210327200206246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="7-Kafka事务"><a href="#7-Kafka事务" class="headerlink" title="7-Kafka事务"></a>7-Kafka事务</h4><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在ExactlyOnce语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<ul>
<li><strong>1 Producer事务</strong></li>
</ul>
<p>– 为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。<br>– 为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和TransactionCoordinator交互获得TransactionID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。<br>tips：如，30个数据，3个broker每个10个数据，第3个broker故障，重复发送，1，2重复，3不重复。上述方法是，PID和客户端事务ID关联，获取到故障前的PID，幂等。</p>
<ul>
<li><strong>2 Consumer事务</strong><br>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的SegmentFile生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</li>
</ul>
<h2 id="二、Kafka-API"><a href="#二、Kafka-API" class="headerlink" title="二、Kafka API"></a>二、Kafka API</h2><h3 id="1-Producer-API"><a href="#1-Producer-API" class="headerlink" title="1.  Producer API"></a>1.  Producer API</h3><h4 id="1-消息发送流程"><a href="#1-消息发送流程" class="headerlink" title="1-消息发送流程"></a>1-消息发送流程</h4><p>– Kafka的Producer发送消息采用的是<strong>异步发送</strong>的方式。在消息发送的过程中，涉及到了<strong>两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator</strong>。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafkabroker。<br>–相关参数：<br>batch.size：只有数据积累到batch.size之后，sender才会发送数据。<br>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据<br><img src="https://img-blog.csdnimg.cn/20210327212719353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210328135809288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="2-异步发送API–producer接口"><a href="#2-异步发送API–producer接口" class="headerlink" title="2-异步发送API–producer接口"></a>2-异步发送API–producer接口</h4><ul>
<li><strong>需要用到的类：</strong></li>
</ul>
<p>– KafkaProducer：需要创建一个生产者对象，用来发送数据<br>– ProducerConfig：获取所需的一系列配置参数<br>– ProducerRecord：每条数据都要封装成一个ProducerRecord对象</p>
<ul>
<li><p><strong>2种实现</strong></p>
</li>
<li><p><strong>1）不带回调函数的API</strong></p>
</li>
<li><p><strong>2）带回调函数的API</strong><br>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p>
</li>
<li><p><em>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。*</em></p>
</li>
</ul>
<h4 id="3-同步发送API–producer接口"><a href="#3-同步发送API–producer接口" class="headerlink" title="3 同步发送API–producer接口"></a>3 同步发送API–producer接口</h4><p>同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p>
<h3 id="2-Consumer-API"><a href="#2-Consumer-API" class="headerlink" title="2. Consumer API"></a>2. Consumer API</h3><ul>
<li><strong>可靠性有保证</strong><br>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</li>
<li><strong>offset必须考虑</strong><br>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</li>
<li><em>所以offset的维护是Consumer消费数据是必须考虑的问题。*</em></li>
</ul>
<h4 id="1-自动提交offset–consumer接口"><a href="#1-自动提交offset–consumer接口" class="headerlink" title="1-自动提交offset–consumer接口"></a>1-自动提交offset–consumer接口</h4><ul>
<li>编写代码需要用到的类：</li>
</ul>
<p>– KafkaConsumer：需要创建一个消费者对象，用来消费数据<br>– ConsumerConfig：获取所需的一系列配置参数<br>– ConsuemrRecord：每条数据都要封装成一个ConsumerRecord对象</p>
<ul>
<li>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。<br>自动提交offset的相关参数：</li>
<li><em>enable.auto.commit*</em>：是否开启自动提交offset功能</li>
<li><em>auto.commit.interval.ms*</em>：自动提交offset的时间间隔以下为自动提交offset的代码：</li>
<li>代码如下：</li>
</ul>
<h4 id="2-手动提交offset–consumer接口"><a href="#2-手动提交offset–consumer接口" class="headerlink" title="2-手动提交offset–consumer接口"></a>2-手动提交offset–consumer接口</h4><ul>
<li><strong>1 手动 Why?</strong><br>虽然自动提交offset十分简介便利，但由于其是基于时间提交的，<strong>开发人员难以把握offset提交的时机</strong>。因此Kafka还提供了手动提交offset的API。</li>
<li><strong>2 两种方法</strong></li>
</ul>
<p>– 手动提交offset的方法有两种：分别是<strong>commitSync（同步提交）和commitAsync（异步提交）</strong>。<br>– 相同点：都会将本次poll的一批数据最高的偏移量提交；<br>– 不同点：commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。<br><strong>1）同步提交</strong><br>offset由于同步提交offset有失败重试机制，故更加可靠，以下为同步提交offset的示例。</p>
<p><strong>2）异步提交offset</strong><br>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交offset的方式。<br>以下为异步提交offset的示例：</p>
<p><strong>3）漏和重复</strong><br>数据漏消费和重复消费分析无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。<br><strong>先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费。</strong></p>
<h4 id="3-自定义存储offset–consumer接口"><a href="#3-自定义存储offset–consumer接口" class="headerlink" title="3-自定义存储offset–consumer接口"></a>3-自定义存储offset–consumer接口</h4><ul>
<li><strong>1 自定义存储offset</strong><br>Kafka0.9版本之前，offset存储在zookeeper，0.9版本及之后，默认将offset存储在Kafka的一个内置的topic中。除此之外，Kafka还可以选择自定义存储offset。</li>
<li><strong>2 消费者Rebalace</strong></li>
</ul>
<p>– offset的维护是相当繁琐的，因为需要考虑到消费者的Rebalace。<br>– <strong>当有新的消费者加入消费者组、已有的消费者推出消费者组或者所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫做Rebalance。</strong><br>–消费者发生Rebalance之后，每个消费者消费的分区就会发生变化。<strong>因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的offset位置继续消费。</strong></p>
<ul>
<li><strong>3 实现Rebalace</strong><br>要实现自定义存储offset，需要借助<strong>ConsumerRebalanceListener</strong>，以下为示例代码，其中提交和获取offset的方法，需要根据所选的offset存储系统自行实现。</li>
</ul>
<h3 id="3-自定义拦截器（Interceptor）"><a href="#3-自定义拦截器（Interceptor）" class="headerlink" title="3. 自定义拦截器（Interceptor）"></a>3. 自定义拦截器（Interceptor）</h3><h4 id="1-拦截器原理"><a href="#1-拦截器原理" class="headerlink" title="1-拦截器原理"></a>1-拦截器原理</h4><ul>
<li><strong>1 概念</strong><br>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要<strong>用于实现clients端的定制化控制逻辑</strong>。</li>
<li><strong>2 原理</strong><br>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。<br>Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</li>
<li><em>（1）configure(configs)*</em><br>获取配置信息和初始化数据时调用。</li>
<li><em>（2）onSend(ProducerRecord)*</em><br>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。<strong>用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区</strong>，否则会影响目标分区的计算。</li>
<li><em>（3）onAcknowledgement(RecordMetadata, Exception)*</em></li>
<li><em>该方法会在消息从RecordAccumulator成功发送到KafkaBroker之后，或者在发送过程中失败时调用。*</em>并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</li>
<li><em>（4）close*</em></li>
<li><em>关闭interceptor，主要用于执行一些资源清理工作*</em><br>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外<strong>倘若指定了多个interceptor，则producer将按照指定顺序调用它们</strong>，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</li>
</ul>
<h4 id="2-拦截器案例"><a href="#2-拦截器案例" class="headerlink" title="2-拦截器案例"></a>2-拦截器案例</h4><p>1）需求：实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。<br><img src="https://img-blog.csdnimg.cn/20210328161857456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>2）案例实操<br>（1）增加时间戳拦截器<br>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器<br>（3） producer主程序<br>3）测试<br>（1）在kafka上启动消费者，然后运行客户端java程序。<br>[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh --bootstrap-serverhadoop102:9092–from-beginning –topic first<br>1501904047034,message0<br>1501904047225,message1<br>1501904047230,message2<br>1501904047234,message3<br>1501904047236,message4<br>1501904047240,message5<br>1501904047243,message6<br>1501904047246,message7<br>1501904047249,message8<br>1501904047252,message9</p>
<h3 id="4-Kafka监控"><a href="#4-Kafka监控" class="headerlink" title="4. Kafka监控"></a>4. Kafka监控</h3><h4 id="1-KafkaEagle"><a href="#1-KafkaEagle" class="headerlink" title="1-KafkaEagle"></a>1-KafkaEagle</h4><p><strong>1.修改kafka启动命令</strong><br>修改kafka-server-start.sh命令中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; &#x3D; &quot;x&quot; ]; then</span><br><span class="line">	export KAFKA_HEAP_OPTS&#x3D;&quot;-Xmx1G -Xms1G&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; &#x3D; &quot;x&quot; ]; then</span><br><span class="line">	export KAFKA_HEAP_OPTS&#x3D;&quot;-server -Xms2G -Xmx2G -XX:PermSize&#x3D;128m -XX:+UseG1GC -XX:MaxGCPauseMillis&#x3D;200 -XX:ParallelGCThreads&#x3D;8 -XX:ConcGCThreads&#x3D;5 -XX:InitiatingHeapOccupancyPercent&#x3D;70&quot;</span><br><span class="line">	export JMX_PORT&#x3D;&quot;9999&quot;</span><br><span class="line">	#export KAFKA_HEAP_OPTS&#x3D;&quot;-Xmx1G -Xms1G&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p><strong>注意：修改之后在启动Kafka之前要分发之其他节点</strong><br>2.上传压缩包kafka-eagle-bin-1.3.7.tar.gz到集群/opt/software目录<br>3.解压到本地<br>[atguigu@hadoop102  software]$   tar -zxvf   kafka-eagle-bin-1.3.7.tar.gz</p>
<p>4.进入刚才解压的目录<br>[atguigu@hadoop102 kafka-eagle-bin-1.3.7]$ ll<br>总用量82932<br>-rw-rw-r–. 1 atguigu atguigu 84920710 8月13 23:00 kafka-eagle-web-1.3.7-bin.tar.gz</p>
<p>5.将kafka-eagle-web-1.3.7-bin.tar.gz解压至/opt/module<br>[atguigu@hadoop102 kafka-eagle-bin-1.3.7]$ tar -zxvf kafka-eagle-web-1.3.7-bin.tar.gz -C /opt/module/</p>
<p>6.修改名称<br>[atguigu@hadoop102 module]$ mv kafka-eagle-web-1.3.7/ eagle</p>
<p>7.给启动文件执行权限[atguigu@hadoop102 eagle]$ cd bin/<br>[atguigu@hadoop102 bin]$ ll<br>总用量12<br>-rw-r–r–. 1 atguigu atguigu 1848 8月22 2017 ke.bat<br>-rw-r–r–. 1 atguigu atguigu 7190 7月30 20:12 ke.sh<br>[atguigu@hadoop102 bin]$chmod 777 ke.sh</p>
<p>8.修改配置文件<br>######################################<br>#multi zookeeper&amp;kafka cluster list<br>######################################<br>kafka.eagle.zk.cluster.alias=cluster1cluster1.zk.list=hadoop102:2181,hadoop103:2181,hadoop104:2181<br>######################################<br>#kafka offset storage<br>######################################<br>cluster1.kafka.eagle.offset.storage=kafka<br>######################################<br>#enable kafka metrics<br>######################################<br>kafka.eagle.metrics.charts=truekafka.eagle.sql.fix.error=false<br>######################################<br>#kafka jdbc driver address<br>######################################<br>kafka.eagle.driver=com.mysql.jdbc.Driverkafka.eagle.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNullkafka.eagle.username=root<br>kafka.eagle.password=000000<br>9.添加环境变量<br>export KE_HOME=/opt/module/eagle<br>export PATH=$PATH:$KE_HOME/bin<br>注意：source /etc/profile<br>10.启动<br>[atguigu@hadoop102 eagle]$ bin/ke.sh start<br>… …<br>… …</p>
<hr>
<p>**</p>
<ul>
<li>Kafka Eagle Service has started success.</li>
<li>Welcome, Now you can visit ‘<a href="http://192.168.9.102:8048/ke&#39;" target="_blank" rel="noopener">http://192.168.9.102:8048/ke&#39;</a></li>
<li>Account:admin ,Password:123456</li>
</ul>
<hr>
<p>**</p>
<ul>
<li><Usage> ke.sh [start|status|stop|restart|stats] </Usage></li>
<li><Usage> <a href="https://www.kafka-eagle.org/" target="_blank" rel="noopener">https://www.kafka-eagle.org/</a> </Usage></li>
</ul>
<hr>
<p>[atguigu@hadoop102 eagle]$<br>注意：启动之前需要先启动ZK以及KAFKA<br>11.登录页面查看监控数据<br><a href="http://192.168.9.102:8048/ke第6章Flume对接Kafka1）配置flume(flume-kafka.conf)#" target="_blank" rel="noopener">http://192.168.9.102:8048/ke第6章Flume对接Kafka1）配置flume(flume-kafka.conf)#</a> definea1.sources = r1a1.sinks = k1<br><img src="https://img-blog.csdnimg.cn/20210328164438403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4NzM0NDAz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="5-其他"><a href="#5-其他" class="headerlink" title="5.其他"></a>5.其他</h3><p>1.Kafka中的ISR(InSyncRepli)、OSR(OutSyncRepli)、AR(AllRepli)代表什么？2.Kafka中的HW、LEO等分别代表什么？3.Kafka中是怎么体现消息顺序性的？4.Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？5.Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？6.“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？7.消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？8.有哪些情形会造成重复消费？9.那些情景会造成消息漏消费？<br>10.当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？1）会在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/first2）触发Controller的监听程序3）kafka Controller 负责topic的创建工作，并更新metadata cache11.topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？12.topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？13.Kafka有内部的topic吗？如果有是什么？有什么所用？14.Kafka分区分配的概念？15.简述Kafka的日志目录结构？16.如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？17.聊一聊Kafka Controller的作用？18.Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？19.失效副本是指什么？有那些应对措施？20.Kafka的哪些设计让它有如此高的性能？</p>
<p>区内有序：一个分区内有序<br>全局有序：一个分区+同步：get方法阻塞send</p>
<p>Kafka选举：Controller 抢资源  Leader选举 ISR  0.9前 响应时间+条数 0.9及后 响应时间</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Java/" rel="tag"># Java</a>
          
            <a href="/tags/%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/" rel="tag"># 框架学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/04/23/aop%EF%BC%8Cioc%EF%BC%8Ccglib%EF%BC%8Cjdk/" rel="next" title="aop，ioc，cglib，jdk">
                <i class="fa fa-chevron-left"></i> aop，ioc，cglib，jdk
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/01/01/Java002/" rel="prev" title="AQS">
                AQS <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">AAlion</p>
              <p class="site-description motion-element" itemprop="description">Happy Code, Happy Life</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、Kafka概念"><span class="nav-number">1.</span> <span class="nav-text">一、Kafka概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-概念"><span class="nav-number">1.1.</span> <span class="nav-text">1. 概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Kafka架构"><span class="nav-number">1.2.</span> <span class="nav-text">2. Kafka架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-基础架构"><span class="nav-number">1.2.1.</span> <span class="nav-text">1-基础架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-工作流程及文件存储机制"><span class="nav-number">1.2.2.</span> <span class="nav-text">2-工作流程及文件存储机制</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-工作流程"><span class="nav-number">1.2.2.0.1.</span> <span class="nav-text">1 工作流程</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-文件存储机制-日志结构"><span class="nav-number">1.2.2.0.2.</span> <span class="nav-text">2 文件存储机制 -日志结构</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-生产者"><span class="nav-number">1.2.3.</span> <span class="nav-text">3-生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-gt-分区策略"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">1&gt; 分区策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-gt-数据可靠性保证—重复、一致"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">2&gt; 数据可靠性保证—重复、一致</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-gt-Exactly-Once语义—精准一次性"><span class="nav-number">1.2.3.3.</span> <span class="nav-text">3&gt; Exactly Once语义—精准一次性</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-消费者"><span class="nav-number">1.2.4.</span> <span class="nav-text">4-消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-gt-消费方式"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">1&gt; 消费方式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-gt-分区分配策略"><span class="nav-number">1.2.4.2.</span> <span class="nav-text">2&gt; 分区分配策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-gt-offset的维护"><span class="nav-number">1.2.4.3.</span> <span class="nav-text">3&gt; offset的维护</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-gt-消费者组案例"><span class="nav-number">1.2.4.4.</span> <span class="nav-text">4&gt; 消费者组案例</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-Kafka-高效读写数据"><span class="nav-number">1.2.5.</span> <span class="nav-text">5-Kafka 高效读写数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-Zookeeper在Kafka中的作用"><span class="nav-number">1.2.6.</span> <span class="nav-text">6-Zookeeper在Kafka中的作用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-Kafka事务"><span class="nav-number">1.2.7.</span> <span class="nav-text">7-Kafka事务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、Kafka-API"><span class="nav-number">2.</span> <span class="nav-text">二、Kafka API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Producer-API"><span class="nav-number">2.1.</span> <span class="nav-text">1.  Producer API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-消息发送流程"><span class="nav-number">2.1.1.</span> <span class="nav-text">1-消息发送流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-异步发送API–producer接口"><span class="nav-number">2.1.2.</span> <span class="nav-text">2-异步发送API–producer接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-同步发送API–producer接口"><span class="nav-number">2.1.3.</span> <span class="nav-text">3 同步发送API–producer接口</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Consumer-API"><span class="nav-number">2.2.</span> <span class="nav-text">2. Consumer API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-自动提交offset–consumer接口"><span class="nav-number">2.2.1.</span> <span class="nav-text">1-自动提交offset–consumer接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-手动提交offset–consumer接口"><span class="nav-number">2.2.2.</span> <span class="nav-text">2-手动提交offset–consumer接口</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-自定义存储offset–consumer接口"><span class="nav-number">2.2.3.</span> <span class="nav-text">3-自定义存储offset–consumer接口</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-自定义拦截器（Interceptor）"><span class="nav-number">2.3.</span> <span class="nav-text">3. 自定义拦截器（Interceptor）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-拦截器原理"><span class="nav-number">2.3.1.</span> <span class="nav-text">1-拦截器原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-拦截器案例"><span class="nav-number">2.3.2.</span> <span class="nav-text">2-拦截器案例</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Kafka监控"><span class="nav-number">2.4.</span> <span class="nav-text">4. Kafka监控</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-KafkaEagle"><span class="nav-number">2.4.1.</span> <span class="nav-text">1-KafkaEagle</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-其他"><span class="nav-number">2.5.</span> <span class="nav-text">5.其他</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AAlion</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
